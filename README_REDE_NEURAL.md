# Rede Neural MLP para Jogo da Velha

## ğŸ“‹ VisÃ£o Geral

ImplementaÃ§Ã£o de uma **Rede Neural MLP (Multi-Layer Perceptron) de 2 camadas** para jogar o jogo da velha, integrada com **Algoritmo GenÃ©tico** conforme especificaÃ§Ãµes fornecidas.

## ğŸ—ï¸ Arquitetura da Rede

```
9 entradas â†’ 9 neurÃ´nios ocultos â†’ 9 saÃ­das
    â†“              â†“                â†“
  x1-x9         tanh()           linear
(tabuleiro)   (ativaÃ§Ã£o)        (scores)
```

### Detalhes TÃ©cnicos:
- **Entrada**: 9 neurÃ´nios (posiÃ§Ãµes do tabuleiro: -1=O, 0=vazio, 1=X)
- **Camada Oculta**: 9 neurÃ´nios com ativaÃ§Ã£o `tanh`
- **Camada SaÃ­da**: 9 neurÃ´nios com ativaÃ§Ã£o linear
- **Total de ParÃ¢metros**: 180 pesos

### Estrutura dos Pesos:
```
W1 (9Ã—9):  81 pesos  (entrada â†’ oculta)
b1 (9):     9 bias   (camada oculta)
W2 (9Ã—9):  81 pesos  (oculta â†’ saÃ­da)  
b2 (9):     9 bias   (camada saÃ­da)
-------------------------------
Total:    180 pesos
```

## ğŸ§¬ IntegraÃ§Ã£o com Algoritmo GenÃ©tico

### Matriz da PopulaÃ§Ã£o
Cada linha da matriz representa um **indivÃ­duo** (rede neural):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚           0 â€¦ 179               â”‚ 180 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤
â”‚ -0.1 | -0.008 | -0.5 | 0.0625â€¦ â”‚ apt â”‚
â”‚ 0.23 | -0.456 | 0.78 | -0.123â€¦ â”‚ apt â”‚
â”‚ â€¦                               â”‚ â€¦   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
```

- **Colunas 0-179**: 180 pesos da rede neural
- **Coluna 180**: FunÃ§Ã£o aptidÃ£o (quanto menor, melhor)
- **Valores**: Pesos aleatÃ³rios entre -1 e 1

## ğŸ“ Arquivos Implementados

### 1. `src/neural_network.py`
ImplementaÃ§Ã£o base da rede neural MLP:
- Classe `RedeNeuralMLP`
- PropagaÃ§Ã£o forward
- Exemplo de uso

### 2. `src/rede_neural_genetica.py`
IntegraÃ§Ã£o com algoritmo genÃ©tico:
- Classe `RedeNeural` (versÃ£o otimizada)
- Classe `PopulacaoGenetica`
- Gerenciamento da matriz de populaÃ§Ã£o

### 3. `src/exemplo_populacao.py`
DemonstraÃ§Ã£o completa:
- Estrutura da matriz conforme imagem
- Teste de propagaÃ§Ã£o
- Exemplos prÃ¡ticos

## ğŸš€ Como Usar

### Exemplo BÃ¡sico
```python
from rede_neural_genetica import PopulacaoGenetica, RedeNeural

# Criar populaÃ§Ã£o genÃ©tica
populacao = PopulacaoGenetica(tamanho_populacao=50)

# Usar um indivÃ­duo como rede neural
rede = populacao.criar_rede_neural(0)

# Testar com tabuleiro do jogo da velha
tabuleiro = np.array([1, 0, -1, 0, 1, 0, 0, -1, 0])
jogada = rede.escolher_jogada(tabuleiro)
print(f"Jogada escolhida: posiÃ§Ã£o {jogada}")
```

### PropagaÃ§Ã£o Manual
```python
# PropagaÃ§Ã£o forward
scores = rede.propagacao(tabuleiro)
print(f"Scores para cada posiÃ§Ã£o: {scores}")
```

## ğŸ” FÃ³rmulas da PropagaÃ§Ã£o

### Camada 1 (Entrada â†’ Oculta)
```
z1 = X @ W1 + b1
h1 = tanh(z1)
```

### Camada 2 (Oculta â†’ SaÃ­da)
```
z2 = h1 @ W2 + b2
y = z2  (ativaÃ§Ã£o linear)
```

Onde:
- `X`: Entrada (9 posiÃ§Ãµes do tabuleiro)
- `W1, W2`: Matrizes de pesos
- `b1, b2`: Vetores de bias
- `@`: Produto matricial

## ğŸ¯ Escolha da Jogada

A rede escolhe a jogada atravÃ©s do **argmax** das saÃ­das, considerando apenas posiÃ§Ãµes livres:

```python
# Mascarar posiÃ§Ãµes ocupadas
scores_masked = np.where(tabuleiro == 0, scores, -inf)

# Escolher posiÃ§Ã£o com maior score
jogada = np.argmax(scores_masked)
```

## ğŸ“Š CaracterÃ­sticas da ImplementaÃ§Ã£o

âœ… **Conformidade com EspecificaÃ§Ãµes**:
- âœ“ Topologia 9Ã—9 com 180 pesos
- âœ“ PropagaÃ§Ã£o forward implementada
- âœ“ IntegraÃ§Ã£o com matriz do algoritmo genÃ©tico
- âœ“ Valores aleatÃ³rios entre -1 e 1
- âœ“ Estrutura 181 colunas (180 pesos + 1 aptidÃ£o)

âœ… **Funcionalidades Extras**:
- âœ“ Classe para gerenciar populaÃ§Ã£o genÃ©tica
- âœ“ MÃ©todos para extrair estatÃ­sticas
- âœ“ Exemplos de uso detalhados
- âœ“ Testes com tabuleiros do jogo da velha

## ğŸ§ª Testando a ImplementaÃ§Ã£o

```bash
# Teste bÃ¡sico da rede neural
python src/neural_network.py

# Teste da integraÃ§Ã£o genÃ©tica
python src/rede_neural_genetica.py

# DemonstraÃ§Ã£o completa
python src/exemplo_populacao.py
```

## ğŸ“ˆ PrÃ³ximos Passos

Para completar o sistema, seria necessÃ¡rio implementar:

1. **FunÃ§Ã£o de AptidÃ£o**: AvaliaÃ§Ã£o atravÃ©s de jogos contra oponentes
2. **Operadores GenÃ©ticos**: SeleÃ§Ã£o, crossover e mutaÃ§Ã£o
3. **Loop Principal**: EvoluÃ§Ã£o da populaÃ§Ã£o ao longo das geraÃ§Ãµes

A implementaÃ§Ã£o atual fornece a **base sÃ³lida** da rede neural conforme especificado, pronta para integraÃ§Ã£o com o algoritmo genÃ©tico completo.

---

**Autor**: ImplementaÃ§Ã£o baseada nas especificaÃ§Ãµes fornecidas  
**Data**: 2025 